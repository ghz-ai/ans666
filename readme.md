# Using Rechours Framework to Evaluate the Effectiveness of ANS Model   **2024/12/31**
Augmented Negative Sampling (ANS)ğŸš€ æ˜¯ä¸€ç§ç”¨äºååŒè¿‡æ»¤æ¨¡å‹çš„å¢å¼ºè´Ÿé‡‡æ ·æŠ€æœ¯![new](/gif/new.gif)
æœ¬é¡¹ç›®å°†ANSæ¨¡å‹ç”¨äºReChorusæ¡†æ¶è¿›è¡Œæµ‹è¯•ğŸ˜ï¼Œç”¨äºå¤„ç†å¤šç§æ¨èç®—æ³•çš„ç ”ç©¶å’Œå¤ç°å·¥ä½œğŸ˜‰
å¢å¼ºè´Ÿé‡‡æ ·ï¼ˆANSï¼‰æ˜¯å¯¹ä¼ ç»Ÿè´Ÿé‡‡æ ·æ–¹æ³•çš„ä¼˜åŒ–æ”¹è¿›ï¼Œä¸“ç”¨äºååŒè¿‡æ»¤æ¨¡å‹ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒANSå¼•å…¥æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚ç‰©å“ç‰¹å¾å’Œç”¨æˆ·åå¥½ï¼Œæ¥å¼ºåŒ–è´Ÿæ ·æœ¬ç”Ÿæˆè¿‡ç¨‹ï¼Œè¿›è€Œæå‡æ¨¡å‹è¡¨ç°åŠ›ä¸æ³›åŒ–èƒ½åŠ›ã€‚åœ¨ååŒè¿‡æ»¤ä¸­ï¼Œè´Ÿæ ·æœ¬é€‰æ‹©å¯¹æ¨¡å‹è®­ç»ƒæ•ˆæœæä¸ºå…³é”®ã€‚

[éƒ­æ€€æ³½çš„ GitHub Page](https://github.com/Zwt122544/ANS).<img src="/gif/github.gif" width="20" height="20">

[ğŸ‘‰ANSçš„è®ºæ–‡åœ°å€](https://arxiv.org/abs/2308.05972)

[ğŸ‘‰ANSçš„githubé¡¹ç›®](https://github.com/Asa9aoTK/ANS-Recbole)
ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€
## Requirement![new](/gif/new.gif)  

<details open>
<summary>ç‚¹å‡»å±•å¼€å®‰è£…ä¾èµ–</summary>

å…‹éš† repoï¼Œå¹¶è¦æ±‚åœ¨ [**Python>=3.8.0**]ğŸŒŸ (https://www.python.org/)  ç¯å¢ƒä¸­å®‰è£…requirements.txt
<img src="/gif/python.gif" width="20" height="20">
```bash
pip install -r requirements.txt
```
å…¶ä¸­åº“åŒ…å«:
- torch==1.12.1
- cudatoolkit==10.2.89
- numpy==1.22.3
- ipython==8.10.0
- jupyter==1.0.0
- tqdm==4.66.1
- pandas==1.4.4
- scikit-learn==1.1.3
- scipy==1.7.3
- pickle
- yaml
</details>

<img src="/gif/fcy2.png" width="500" height="500"> <img src="/gif/fcy1.png" width="300" height="300">

 å®éªŒç»“æœå’Œåˆ†æä¸ºäº†éªŒè¯ANSæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šä¸ªè¯„ä»·æŒ‡æ ‡è¿›è¡Œäº†å®éªŒï¼ŒåŒ…æ‹¬ç²¾ 
åº¦@kã€å¬å›ç‡@kã€F1è¯„åˆ†å’Œå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ã€‚
å®éªŒè®¾ç½®å®éªŒä½¿ç”¨äº†150,000 æ•°æ®é›†, è¯¥æ•°æ®é›†åŒ…å«å¤§çº¦150,000 ä¸ªç”¨æˆ·-ç‰©å“è¯„çº§äº¤äº’ã€‚æˆ‘ä»¬ä½¿ 
ç”¨85% çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå‰©ä¸‹çš„15%ç”¨äºæµ‹è¯•ã€‚é€šè¿‡ç½‘æ ¼æœç´¢å¯¹è¶…å‚æ•°ï¼ˆå¦‚åµŒå…¥ç»´åº¦ã€å­¦ä¹ ç‡ï¼‰è¿›è¡Œ äº†ä¼˜åŒ–ã€‚

<img src="/gif/fcy3.png" width="300" height="300">
## ANSæ¨¡å‹ç»“æ„
<img src="/gif/structure.png">

 (1)å¢å¼ºè´Ÿæ ·æœ¬çš„ç”Ÿæˆ
ä¼ ç»Ÿçš„è´Ÿé‡‡æ ·æ–¹æ³•é€šå¸¸éšæœºé€‰æ‹©æœªäº¤äº’çš„ç”¨æˆ·-ç‰©å“å¯¹ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œè¿™ç§æ–¹æ³•ç”Ÿæˆçš„è´Ÿæ ·æœ¬å¯èƒ½ç¼ºä¹åŒºåˆ†åº¦ï¼Œå¯¼è‡´æ¨¡å‹è®­ç»ƒæ•ˆç‡ä½ä¸‹ã€‚è€Œå¢å¼ºè´Ÿé‡‡æ ·é€šè¿‡è€ƒè™‘ç‰©å“çš„ç‰¹å¾å’Œç”¨æˆ·çš„å†å²è¡Œä¸ºï¼Œç”Ÿæˆæ›´å…·ä¿¡æ¯æ€§å’ŒæŒ‘æˆ˜æ€§çš„è´Ÿæ ·æœ¬ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°å­¦ä¹ ç”¨æˆ·ä¸ç‰©å“ä¹‹é—´çš„æ½œåœ¨äº¤äº’æ¨¡å¼ã€‚

 ï¼ˆ2ï¼‰.åŒºåˆ†éš¾æ˜“è´Ÿæ ·æœ¬
éš¾è´Ÿæ ·æœ¬æ˜¯æŒ‡é‚£äº›ä¸æ­£æ ·æœ¬åœ¨ç‰¹å¾ä¸Šéå¸¸ç›¸ä¼¼ä½†ç”¨æˆ·å¹¶æœªä¸ä¹‹äº¤äº’çš„ç‰©å“ï¼Œè¿™äº›æ ·æœ¬å¯¹æ¨¡å‹çš„è®­ç»ƒæ›´å…·æŒ‘æˆ˜æ€§ã€‚æ˜“è´Ÿæ ·æœ¬åˆ™æ˜¯ä¸æ­£æ ·æœ¬åœ¨ç‰¹å¾ä¸Šå·®å¼‚è¾ƒå¤§çš„ç‰©å“ï¼Œç›¸å¯¹å®¹æ˜“è¢«æ¨¡å‹è¯†åˆ«ã€‚é€šè¿‡åŒºåˆ†éš¾æ˜“è´Ÿæ ·æœ¬ï¼Œæ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°å­¦ä¹ ï¼Œæé«˜åŒºåˆ†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚

 ï¼ˆ3ï¼‰. å¤šæºç‰¹å¾èåˆ
ä¼ ç»Ÿçš„è´Ÿé‡‡æ ·æ–¹æ³•é€šå¸¸åªè€ƒè™‘ç”¨æˆ·-ç‰©å“å¯¹çš„äº¤äº’ä¿¡æ¯ï¼Œè€Œå¢å¼ºè´Ÿé‡‡æ ·é€šè¿‡èåˆå¤šæºç‰¹å¾ï¼Œå¦‚ç”¨æˆ·çš„å…´è¶£åå¥½ã€ç‰©å“çš„ç±»åˆ«å’Œæ ‡ç­¾ç­‰ï¼Œç”Ÿæˆæ›´ä¸°å¯Œçš„è´Ÿæ ·æœ¬ã€‚è¿™ç§å¤šæºç‰¹å¾èåˆä¸ä»…æé«˜äº†è´Ÿæ ·æœ¬çš„è´¨é‡ï¼Œè¿˜ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å…¨é¢åœ°ç†è§£ç”¨æˆ·å’Œç‰©å“çš„ç‰¹å¾ï¼Œä»è€Œæé«˜æ¨èçš„å‡†ç¡®æ€§å’Œä¸ªæ€§åŒ–ç¨‹åº¦ã€‚

ï¼ˆ4ï¼‰. åŠ¨æ€è´Ÿæ ·æœ¬é€‰æ‹©
-åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šä¸æ–­å˜åŒ–ã€‚åŠ¨æ€è´Ÿæ ·æœ¬é€‰æ‹©æ–¹æ³•å¯ä»¥æ ¹æ®æ¨¡å‹çš„å½“å‰æ€§èƒ½ï¼ŒåŠ¨æ€è°ƒæ•´è´Ÿæ ·æœ¬çš„é€‰æ‹©ç­–ç•¥ï¼Œé€‰æ‹©æ›´å…·æŒ‘æˆ˜æ€§çš„è´Ÿæ ·æœ¬ï¼Œä½¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å§‹ç»ˆä¿æŒé«˜æ•ˆçš„å­¦ä¹ çŠ¶æ€ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é¿å…æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œæé«˜æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½ã€‚

**ğŸš€ ç‚¹å‡»å±•å¼€æŸ¥çœ‹ä»£ç **
<details open>
  
  
  ```python
class ANS(GeneralRecommender):
  input_type = InputType.PAIRWISE

  def __init__(self, config, dataset):
      super(ANS, self).__init__(config, dataset)
      self.emb_size = config["embedding_size"]
      # load dataset info
      self.interaction_matrix = dataset.inter_matrix(form="coo").astype(np.float32)
      self.neg_seq_len = config["train_neg_sample_args"]["sample_num"]
      # load parameters info
      self.latent_dim = config[
          "embedding_size"
      ]  # int type:the embedding size of lightGCN
      self.n_layers = config["n_layers"]
      self.reg_weight = config[
          "reg_weight"
      ]  # float32 type: the weight decay for l2 normalization
      self.require_pow = config["require_pow"]

      # define layers and loss
      self.user_embedding = torch.nn.Embedding(
          num_embeddings=self.n_users, embedding_dim=self.latent_dim
      )
      self.item_embedding = torch.nn.Embedding(
          num_embeddings=self.n_items, embedding_dim=self.latent_dim
      )
      self.mf_loss = BPRLoss()
      self.reg_loss = EmbLoss()

      # storage variables for full sort evaluation acceleration
      self.restore_user_e = None
      self.restore_item_e = None

      # generate intermediate data
      self.norm_adj_matrix = self.get_norm_adj_mat().to(self.device)

      # parameters initialization
      self.apply(xavier_uniform_initialization)
      self.user_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.item_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.pos_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.neg_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.hard_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.conf_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.easy_gate = nn.Linear(self.emb_size, self.emb_size).to(self.device)
      self.margin_model = nn.Linear(self.emb_size, 1).to(self.device)
      self.eps=config["eps"]
      self.gamma=config["gamma"]

      self.other_parameter_name = ["restore_user_e", "restore_item_e"]

  def get_norm_adj_mat(self):
      r"""Get the normalized interaction matrix of users and items.

      Construct the square matrix from the training data and normalize it
      using the laplace matrix.

      .. math::
          A_{hat} = D^{-0.5} \times A \times D^{-0.5}

      Returns:
          Sparse tensor of the normalized interaction matrix.
      """
      # build adj matrix
      A = sp.dok_matrix(
          (self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32
      )
      inter_M = self.interaction_matrix
      inter_M_t = self.interaction_matrix.transpose()
      data_dict = dict(
          zip(zip(inter_M.row, inter_M.col + self.n_users), [1] * inter_M.nnz)
      )
      data_dict.update(
          dict(
              zip(
                  zip(inter_M_t.row + self.n_users, inter_M_t.col),
                  [1] * inter_M_t.nnz,
              )
          )
      )
      A._update(data_dict)
      # norm adj matrix
      sumArr = (A > 0).sum(axis=1)
      # add epsilon to avoid divide by zero Warning
      diag = np.array(sumArr.flatten())[0] + 1e-7
      diag = np.power(diag, -0.5)
      D = sp.diags(diag)
      L = D * A * D
      # covert norm_adj matrix to tensor
      L = sp.coo_matrix(L)
      row = L.row
      col = L.col
      i = torch.LongTensor(np.array([row, col]))
      data = torch.FloatTensor(L.data)
      SparseL = torch.sparse.FloatTensor(i, data, torch.Size(L.shape))
      return SparseL

  def get_ego_embeddings(self):
      r"""Get the embedding of users and items and combine to an embedding matrix.

      Returns:
          Tensor of the embedding matrix. Shape of [n_items+n_users, embedding_dim]
      """
      user_embeddings = self.user_embedding.weight
      item_embeddings = self.item_embedding.weight
      ego_embeddings = torch.cat([user_embeddings, item_embeddings], dim=0)
      return ego_embeddings

  def forward(self):
      all_embeddings = self.get_ego_embeddings()
      embeddings_list = [all_embeddings]

      for layer_idx in range(self.n_layers):
          all_embeddings = torch.sparse.mm(self.norm_adj_matrix, all_embeddings)
          embeddings_list.append(all_embeddings)

      lightgcn_all_embeddings = torch.stack(embeddings_list, dim=1)
      embs = lightgcn_all_embeddings
      return embs[:self.n_users, :], embs[self.n_users:, :]
  



  def calculate_loss(self, interaction):
      # clear the storage variable when training
      if self.restore_user_e is not None or self.restore_item_e is not None:
          self.restore_user_e, self.restore_item_e = None, None

      user = interaction[self.USER_ID]
      pos_item = interaction[self.ITEM_ID]
      neg_item = interaction[self.NEG_ITEM_ID]
      neg_item_seq = neg_item.reshape((self.neg_seq_len, -1))
      neg_item_seq = neg_item_seq.T

      neg_item = neg_item_seq
      user_number = int(len(user) / self.neg_seq_len)
      user = user[0:user_number]
      pos_item = pos_item[0:user_number]

      user_all_embeddings, item_all_embeddings = self.forward()
      u_embeddings = user_all_embeddings[user]
      pos_embeddings = item_all_embeddings[pos_item]
      neg_embeddings = item_all_embeddings[neg_item]




      s_e = u_embeddings
      p_e = pos_embeddings
      n_e = neg_embeddings
      batch_size = user.shape[0]
      
      gate_neg_hard = torch.sigmoid(self.item_gate(n_e) * self.user_gate(s_e).unsqueeze(1))
      n_hard =  n_e * gate_neg_hard
      n_easy =  n_e - n_hard
      
      p_hard =  p_e.unsqueeze(1) * gate_neg_hard
      p_easy =  p_e.unsqueeze(1) - p_hard
  
      import torch.nn.functional as F
      distance = torch.mean(F.pairwise_distance(n_hard, p_hard, p=2).squeeze(dim=1))
      temp = torch.norm(torch.mul(p_easy, n_easy),dim=-1)
      orth = torch.mean(torch.sum(temp,axis=-1))

      margin = torch.sigmoid(1/self.margin_model(n_hard * p_hard))

      random_noise = torch.rand(n_easy.shape).to(self.device)
      magnitude = torch.nn.functional.normalize(random_noise, p=2, dim=-1) * margin *0.1
      direction = torch.sign(p_easy - n_easy)
      noise = torch.mul(direction,magnitude)
      n_easy_syth = noise + n_easy
      n_e_ = n_hard + n_easy_syth        
      hard_scores = torch.sum(torch.mul(s_e.unsqueeze(dim=1), n_hard), axis=-1)  # [batch_size, K]
      easy_scores = torch.sum(torch.mul(s_e.unsqueeze(dim=1), n_easy), axis=-1)  # [batch_size, K]
      syth_scores = torch.sum(torch.mul(s_e.unsqueeze(dim=1), n_e_), axis=-1)  # [batch_size, K]
      norm_scores = torch.sum(torch.mul(s_e.unsqueeze(dim=1), n_e), axis=-1)  # [batch_size, K]
      sns_loss = torch.mean(torch.log(1 + torch.exp(easy_scores - hard_scores).sum(dim=1)))
      dis_loss = distance + orth
      scores = (s_e.unsqueeze(dim=1) * n_e_).sum(dim=-1)  # [batch_size, n_negs]
      scores_false =  syth_scores - norm_scores

      indices = torch.max(scores + self.eps*scores_false, dim=1)[1].detach()
      neg_items_emb_ = n_e_.permute([0, 2, 1, 3])  # [batch_size, n_hops+1, n_negs, channel]
      # [batch_size, n_hops+1, channel]
      neg_embeddings = neg_items_emb_[[[i] for i in range(batch_size)],range(neg_items_emb_.shape[1]), indices, :]
      

      # calculate BPR Loss
      pos_scores = torch.mul(u_embeddings, pos_embeddings).sum(dim=1).squeeze(dim=1).sum(dim=-1)
      neg_scores = torch.mul(u_embeddings, neg_embeddings).sum(dim=1).sum(dim=1)
      mf_loss = self.mf_loss(pos_scores, neg_scores)

      # calculate BPR Loss
      u_ego_embeddings = self.user_embedding(user)
      pos_ego_embeddings = self.item_embedding(pos_item)
      neg_ego_embeddings = self.item_embedding(neg_item)

      reg_loss = self.reg_loss(
          u_ego_embeddings,
          pos_ego_embeddings,
          neg_ego_embeddings,
          require_pow=self.require_pow,
      )


      loss = mf_loss + self.reg_weight * reg_loss + self.gamma * (sns_loss + dis_loss)
      # loss = mf_loss + self.gamma * (sns_loss)
      return loss

  def predict(self, interaction):
      user = interaction[self.USER_ID]
      item = interaction[self.ITEM_ID]

      user_all_embeddings, item_all_embeddings = self.forward()

      u_embeddings = user_all_embeddings[user]
      i_embeddings = item_all_embeddings[item]
      scores = torch.mul(u_embeddings, i_embeddings).sum(dim=1)
      return scores

  def full_sort_predict(self, interaction):
      user = interaction[self.USER_ID]
      user_e = self.user_embedding(user)
      all_item_e = self.item_embedding.weight
      score = torch.matmul(user_e, all_item_e.transpose(0, 1))
      return score.view(-1)
 ```
</details>
<img src="/gif/fcy4.png" width="500" height="300">

## æ¨¡å‹ç»“æœå±•ç¤º

| Data                     | Metric                | AutoCF                 | LightGCN               | FPMC                   | SLRPlus                | GRU4Rec                | NeuMF                  |
|:-------------------------|:----------------------|------------------------|------------------------|------------------------|------------------------|------------------------|------------------------|
| Grocery_and_Gourmet_Food | HR@5</br><br/>NDCG@5  | 0.1121</br><br/>0.0465 | 0.3858</br><br/>0.2659 | 0.3409</br><br/>0.2606 | 0.3242</br><br/>0.2249 | 0.3682</br><br/>0.2616 | 0.3261</br><br/>0.2242 |
| MIND_Large               | HR@5</br><br/>NDCG@5  | 0.2537</br><br/>0.0807 | 0.1078</br><br/>0.0631 | 0.1804</br><br/>0.1207 | 0.1098</br><br/>0.0716 | 0.2010</br><br/>0.1221 | 0.1020</br><br/>0.0638 |
| MovieLens-1M             | HR@5</br><br/>NDCG@5  | 0.6763</br><br/>0.2832 | 0.3520</br><br/>0.2382 | 0.4181</br><br/>0.2939 | 0.3693</br><br/>0.2455 | 0.4167</br><br/>0.2859 | 0.3319</br><br/>0.2277 |


å®éªŒåˆ†æç»“æœè¡¨æ˜ï¼ŒANSæ¨¡å‹åœ¨æ‰€æœ‰è¯„ä»·æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä¼ ç»Ÿçš„ååŒæ»¤æ³¢æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç²¾ 
åº¦@10å’ŒRecall@10æ–¹é¢ã€‚è¿™è¡¨æ˜ANSäº§ç”Ÿäº†æ›´å‡†ç¡®å’Œç›¸å…³çš„å»ºè®®ã€‚æ­¤å¤–ï¼ŒANSåœ¨MSEæ–¹é¢ä¹Ÿè¡¨ç°å‡ºäº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œè¿™è¡¨æ˜ä¸å…¶ä»–æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒæä¾›äº†æ›´å‡†ç¡®çš„è¯„çº§é¢„æµ‹ã€‚


## Usage
æ·»åŠ å®Œæ•°æ®é›†å
è¿è¡Œä¸‹é¢çš„å‘½ä»¤ï¼š
```
python main.py --model_name ANS --emb_size 64 --lr 1e-3 --l2 0 --loss_n BPR --dataset ML_1MCTR --path ../data/ --metric NDCG,HR --topk 1,2,3,5,10 --main_metric NDCG@2 --model_mode Impression
```

- `--model_name`: æ¨¡å‹
- `--dataset`: æ•°æ®é›†åç§°
- `--path`: æ•°æ®é›†è·¯å¾„


åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¿ç”¨Rechoursæ¡†æ¶å¯¹ANSï¼ˆåŸºäºæ³¨æ„åŠ›çš„é‚»åŸŸé‡‡æ ·ï¼‰æ¨¡å‹çš„æœ‰æ•ˆæ€§è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚å®éªŒæˆæœæ­ç¤ºï¼ŒANSæ¨¡å‹åœ¨è¯¸å¤šå…³é”®è¯„ä¼°ç»´åº¦ä¸Šå‡å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œæ¶µç›–æ¨èç²¾å‡†åº¦ã€å¬å›ç‡ã€F1åˆ†æ•°ä»¥åŠè¯„åˆ†é¢„æµ‹ç²¾å‡†åº¦ç­‰å¤šä¸ªæ–¹é¢ï¼Œå‡æ˜¾è‘—è¶…è¶Šä¼ ç»ŸååŒè¿‡æ»¤æ‰‹æ®µåŠçŸ©é˜µåˆ†è§£æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç²¾å‡†æŠŠæ¡ç”¨æˆ·ä¸é¡¹ç›®é—´çš„æ½œåœ¨äº’åŠ¨å…³è”ï¼Œæœ‰æ•ˆæå‡äº†æ¨èçš„ç²¾å‡†åº¦ä¸å¤šæ ·æ€§ï¼Œè¿›è€Œå¼ºåŒ–äº†æ¨¡å‹çš„æ³›åŒ–å®åŠ›ã€‚
## License

This project is licensed under the MIT License. It references ideas and methodologies from the following projects:

- **[ğŸ‘‰ANSçš„è®ºæ–‡åœ°å€](https://arxiv.org/abs/2308.05972)**
- **[ğŸ‘‰ANSçš„githubé¡¹ç›®](https://github.com/Asa9aoTK/ANS-Recbole)**

